{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "loose-scanner",
   "metadata": {},
   "source": [
    "# Linear Bivariate BMM and calibration with JETSCAPE models : Add Step Asym mixing\n",
    "\n",
    "<!-- The best way to learn Taweret is to use it. You can run, modify and experiment with this notebook [here.](https://mybinder.org/v2/gh/danOSU/Taweret/c2d8fd3ce3d74a5891d51adb5afc0afa0b503127?urlpath=lab%2Ftree%2Fdocs%2Fsource%2Fnotebooks%2FLinear_BMM_with_step_function_for_SAMBA_models.ipynb) -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-dublin",
   "metadata": {},
   "source": [
    "This notebook shows how to use the Bayesian model mixing package **Taweret** for a toy problem. \n",
    "\n",
    "Author : Dan Liyanage \n",
    "\n",
    "Date : 01/03/2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "after-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using idf = 3 : Pratt-Torrieri-Bernhard\n",
      "SystemsInfo = \n",
      "{'Pb-Pb-2760': {'proj': 'Pb', 'targ': 'Pb', 'sqrts': 2760, 'main_design_file': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat', 'main_range_file': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production/design_ranges_main_PbPb-2760.dat', 'validation_design_file': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production/design_points_validation_PbPb-2760.dat', 'validation_range_file': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production//design_ranges_validation_PbPb-2760.dat', 'labels': ['$N$[$2.76$TeV]', '$p$', '$\\\\sigma_k$', '$w$ [fm]', '$d_{\\\\mathrm{min}}$ [fm]', '$\\\\tau_R$ [fm/$c$]', '$\\\\alpha$', '$T_{\\\\eta,\\\\mathrm{kink}}$ [GeV]', '$a_{\\\\eta,\\\\mathrm{low}}$ [GeV${}^{-1}$]', '$a_{\\\\eta,\\\\mathrm{high}}$ [GeV${}^{-1}$]', '$(\\\\eta/s)_{\\\\mathrm{kink}}$', '$(\\\\zeta/s)_{\\\\max}$', '$T_{\\\\zeta,c}$ [GeV]', '$w_{\\\\zeta}$ [GeV]', '$\\\\lambda_{\\\\zeta}$', '$b_{\\\\pi}$', '$T_{\\\\mathrm{sw}}$ [GeV]'], 'main_events_dir': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/model_calculations/production_500pts_Pb_Pb_2760/Events/main', 'validation_events_dir': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/model_calculations/production_500pts_Pb_Pb_2760/Events/validation', 'main_obs_file': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/model_calculations/production_500pts_Pb_Pb_2760/Obs/main.dat', 'validation_obs_file': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/model_calculations/production_500pts_Pb_Pb_2760/Obs/validation.dat', 'n_design': 500, 'n_validation': 100, 'design_remove_idx': [322, 324, 326, 459, 462, 464, 468, 341, 406, 280, 285, 289, 482, 483, 485, 232, 495, 432, 242, 440, 377, 123, 60, 447], 'npc': 10, 'MAP_obs_file': '/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/model_calculations/MAP/PTB/Obs/obs_Pb-Pb-2760.dat'}}\n",
      "The active observable list for calibration: {'Pb-Pb-2760': ['dNch_deta', 'dET_deta', 'dN_dy_pion', 'dN_dy_kaon', 'dN_dy_proton', 'mean_pT_pion', 'mean_pT_kaon', 'mean_pT_proton', 'pT_fluct', 'v22', 'v32', 'v42']}\n",
      "Loading Pb-Pb-2760 main calculations from /Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/model_calculations/production_500pts_Pb_Pb_2760/Obs/main.dat\n",
      "ds.shape = (500,)\n",
      "Design points which will be deleted from training : [322, 324, 326, 459, 462, 464, 468, 341, 406, 280, 285, 289, 482, 483, 485, 232, 495, 432, 242, 440, 377, 123, 60, 447]\n",
      "Loading Pb-Pb-2760 MAP calculations from /Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/model_calculations/MAP/PTB/Obs/obs_Pb-Pb-2760.dat\n",
      "No MAP calculations found for system Pb-Pb-2760\n",
      "WARNING! Can't load emulator for system Pb-Pb-2760 for idf 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"WORKDIR\"] = \"/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes\"\n",
    "# You will have to change the following imports depending on where you have \n",
    "# the packages installed\n",
    "# If using binder please uncomment the followings.\n",
    "#sys.path.append(\"/home/jovyan/\")\n",
    "sys.path.append(\"/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/src\")\n",
    "sys.path.append(\"/Users/dananjayaliyanage/git/Taweret/\")\n",
    "\n",
    "from configurations import *\n",
    "from emulator import *\n",
    "#sys.path.append(\"/Users/dananjayaliyanage/git/Taweret\")\n",
    "#sys.path.append(\"/Users/dananjayaliyanage/git/Taweret/subpackages/SAMBA\")\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "# To define priors. (uncoment if not using default priors)\n",
    "#import bilby\n",
    "\n",
    "# For other operations\n",
    "import numpy as np\n",
    "import bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49e91e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes\n"
     ]
    }
   ],
   "source": [
    "!echo ${WORKDIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c9f9f",
   "metadata": {},
   "source": [
    "## 1. Get toy models and the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28900f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_to_remove = ['dN_dy_Lambda', 'dN_dy_Omega', 'dN_dy_Xi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loaded-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading experimental data from /Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/HIC_experimental_data\n",
      "Loading main points from /Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat\n",
      "Loading main ranges from /Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production/design_ranges_main_PbPb-2760.dat\n",
      "Summary of design : \n",
      "Loading main points from /Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production/design_points_main_PbPb-2760.dat\n",
      "Loading main ranges from /Users/dananjayaliyanage/git/Taweret/subpackages/js-sims-bayes/production_designs/design_pts_Pb_Pb_2760_production/design_ranges_main_PbPb-2760.dat\n",
      "Summary of design : \n"
     ]
    }
   ],
   "source": [
    "# Toy models from SAMBA\n",
    "from Taweret.models import jetscape_sims_models as sims\n",
    "\n",
    "m1 = sims.jetscape_models_pb_pb_2760(fix_MAP=False,model_num=0, obs_to_remove=obs_to_remove)\n",
    "m2 = sims.jetscape_models_pb_pb_2760(fix_MAP=False,model_num=3, obs_to_remove=obs_to_remove)\n",
    "exp = sims.exp_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedf5bf",
   "metadata": {},
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed28bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_grad = np.array(MAP_params['Pb-Pb-2760']['Grad'])\n",
    "map_ptb = np.array(MAP_params['Pb-Pb-2760']['PTB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8120dcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_ptb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lasting-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.linspace(0, 60, 20)\n",
    "plot_g = np.linspace(0.0,60,100)\n",
    "m1_prediction = m1.evaluate(g, map_grad)\n",
    "m2_prediction = m2.evaluate(g, map_ptb)\n",
    "#true_output = truth.evaluate(plot_g)\n",
    "exp_data= exp.evaluate(g,obs_to_remove=obs_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dimensional-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_names = list(obs_cent_list['Pb-Pb-2760'].keys())\n",
    "# for i in obs_to_remove:\n",
    "#     obs_names.remove(i)\n",
    "# print(obs_names)\n",
    "# for i in range(0,12):\n",
    "#     fig, ax_f = plt.subplots(figsize=(10,10))\n",
    "#     ax_f.plot(g, m1_prediction[0][:,i].flatten(), label='Grad')\n",
    "#     ax_f.plot(g, m2_prediction[0][:,i].flatten(), label='PTB')\n",
    "#     #ax_f.plot(plot_g, true_output[0], label='truth')\n",
    "#     #ax_f.scatter(g,exp_data[0][:,i].flatten(), marker='x', label='experimental data')\n",
    "#     ax_f.set_xlabel('Centrality')\n",
    "#     ax_f.errorbar(g,exp_data[0][:,i].flatten(), \n",
    "#                 yerr=exp_data[1][:,i].flatten(),\n",
    "#                 marker='x', label='experimental data')\n",
    "#     #ax_f.set_ylim(1.2,3.2)\n",
    "#     ax_f.set_ylabel(obs_names[i])\n",
    "#     ax_f.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-application",
   "metadata": {},
   "source": [
    "##  2. Choose a Mixing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2278f990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Taweret.core.base_model import BaseModel\n",
    "isinstance(m1, BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thorough-exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addstepasym mixing function has 3 free parameter(s)\n",
      "Warning : Default prior is set to {'addstepasym_0': Uniform(minimum=0, maximum=1, name='addstepasym_0', latex_label='addstepasym_0', unit=None, boundary=None), 'addstepasym_1': Uniform(minimum=0, maximum=1, name='addstepasym_1', latex_label='addstepasym_1', unit=None, boundary=None), 'addstepasym_2': Uniform(minimum=0, maximum=1, name='addstepasym_2', latex_label='addstepasym_2', unit=None, boundary=None)}\n",
      "To change the prior use `set_prior` method\n"
     ]
    }
   ],
   "source": [
    "# Mixing method\n",
    "from Taweret.mix.bivariate_linear import BivariateLinear as BL\n",
    "\n",
    "models= {'Grad':m1,'PTB':m2}\n",
    "mix_model = BL(models_dic=models, method='addstepasym', nargs_model_dic={'Grad':17, 'PTB':17}, same_parameters = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18aae651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addstep_0': Uniform(minimum=0, maximum=60, name='addstep_0', latex_label='addstep_0', unit=None, boundary=None),\n",
       " 'addstep_1': Uniform(minimum=0, maximum=60, name='addstep_1', latex_label='addstep_1', unit=None, boundary=None),\n",
       " 'addstep_2': Uniform(minimum=0, maximum=1, name='addstep_2', latex_label='addstep_2', unit=None, boundary=None),\n",
       " 'Grad_0': Uniform(minimum=10.0, maximum=20.0, name='Grad_0', latex_label='Grad_0', unit=None, boundary=None),\n",
       " 'Grad_1': Uniform(minimum=-0.7, maximum=0.7, name='Grad_1', latex_label='Grad_1', unit=None, boundary=None),\n",
       " 'Grad_2': Uniform(minimum=0.3, maximum=2.0, name='Grad_2', latex_label='Grad_2', unit=None, boundary=None),\n",
       " 'Grad_3': Uniform(minimum=0.5, maximum=1.5, name='Grad_3', latex_label='Grad_3', unit=None, boundary=None),\n",
       " 'Grad_4': Uniform(minimum=0.0, maximum=4.913, name='Grad_4', latex_label='Grad_4', unit=None, boundary=None),\n",
       " 'Grad_5': Uniform(minimum=0.3, maximum=2.0, name='Grad_5', latex_label='Grad_5', unit=None, boundary=None),\n",
       " 'Grad_6': Uniform(minimum=-0.3, maximum=0.3, name='Grad_6', latex_label='Grad_6', unit=None, boundary=None),\n",
       " 'Grad_7': Uniform(minimum=0.13, maximum=0.3, name='Grad_7', latex_label='Grad_7', unit=None, boundary=None),\n",
       " 'Grad_8': Uniform(minimum=-2.0, maximum=1.0, name='Grad_8', latex_label='Grad_8', unit=None, boundary=None),\n",
       " 'Grad_9': Uniform(minimum=-1.0, maximum=2.0, name='Grad_9', latex_label='Grad_9', unit=None, boundary=None),\n",
       " 'Grad_10': Uniform(minimum=0.01, maximum=0.2, name='Grad_10', latex_label='Grad_10', unit=None, boundary=None),\n",
       " 'Grad_11': Uniform(minimum=0.01, maximum=0.2, name='Grad_11', latex_label='Grad_11', unit=None, boundary=None),\n",
       " 'Grad_12': Uniform(minimum=0.12, maximum=0.3, name='Grad_12', latex_label='Grad_12', unit=None, boundary=None),\n",
       " 'Grad_13': Uniform(minimum=0.025, maximum=0.15, name='Grad_13', latex_label='Grad_13', unit=None, boundary=None),\n",
       " 'Grad_14': Uniform(minimum=-0.8, maximum=0.8, name='Grad_14', latex_label='Grad_14', unit=None, boundary=None),\n",
       " 'Grad_15': Uniform(minimum=2.0, maximum=8.0, name='Grad_15', latex_label='Grad_15', unit=None, boundary=None),\n",
       " 'Grad_16': Uniform(minimum=0.13, maximum=0.165, name='Grad_16', latex_label='Grad_16', unit=None, boundary=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uncoment to change the prior from the default\n",
    "priors = bilby.core.prior.PriorDict()\n",
    "priors['addstep_0'] = bilby.core.prior.Uniform(0, 60, name=\"addstep_0\")\n",
    "priors['addstep_1'] = bilby.core.prior.Uniform(0, 60, name=\"addstep_1\")\n",
    "priors['addstep_2'] = bilby.core.prior.Uniform(0, 1, name=\"addstep_2\")\n",
    "mix_model.set_prior(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b6cc1",
   "metadata": {},
   "source": [
    "## 3. Train to find posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb56060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler_args = {'sampler': 'ptemcee', 'ntemps': 5, 'nwalkers': 20, 'Tmax': 100, 'burn_in_fixed_discard': 200, 'nsamples': 2000, 'printdt': 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64973d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5a0b6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:43 bilby INFO    : Running for label 'addstepasym_mix', output will be saved to 'outdir/calibration_grad_ptb_addstepasym'\n",
      "14:43 bilby INFO    : Search parameters:\n",
      "14:43 bilby INFO    :   addstep_0 = Uniform(minimum=0, maximum=60, name='addstep_0', latex_label='addstep_0', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   addstep_1 = Uniform(minimum=0, maximum=60, name='addstep_1', latex_label='addstep_1', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   addstep_2 = Uniform(minimum=0, maximum=1, name='addstep_2', latex_label='addstep_2', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_0 = Uniform(minimum=10.0, maximum=20.0, name='Grad_0', latex_label='Grad_0', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_1 = Uniform(minimum=-0.7, maximum=0.7, name='Grad_1', latex_label='Grad_1', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_2 = Uniform(minimum=0.3, maximum=2.0, name='Grad_2', latex_label='Grad_2', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_3 = Uniform(minimum=0.5, maximum=1.5, name='Grad_3', latex_label='Grad_3', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_4 = Uniform(minimum=0.0, maximum=4.913, name='Grad_4', latex_label='Grad_4', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_5 = Uniform(minimum=0.3, maximum=2.0, name='Grad_5', latex_label='Grad_5', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_6 = Uniform(minimum=-0.3, maximum=0.3, name='Grad_6', latex_label='Grad_6', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_7 = Uniform(minimum=0.13, maximum=0.3, name='Grad_7', latex_label='Grad_7', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_8 = Uniform(minimum=-2.0, maximum=1.0, name='Grad_8', latex_label='Grad_8', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_9 = Uniform(minimum=-1.0, maximum=2.0, name='Grad_9', latex_label='Grad_9', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_10 = Uniform(minimum=0.01, maximum=0.2, name='Grad_10', latex_label='Grad_10', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_11 = Uniform(minimum=0.01, maximum=0.2, name='Grad_11', latex_label='Grad_11', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_12 = Uniform(minimum=0.12, maximum=0.3, name='Grad_12', latex_label='Grad_12', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_13 = Uniform(minimum=0.025, maximum=0.15, name='Grad_13', latex_label='Grad_13', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_14 = Uniform(minimum=-0.8, maximum=0.8, name='Grad_14', latex_label='Grad_14', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_15 = Uniform(minimum=2.0, maximum=8.0, name='Grad_15', latex_label='Grad_15', unit=None, boundary=None)\n",
      "14:43 bilby INFO    :   Grad_16 = Uniform(minimum=0.13, maximum=0.165, name='Grad_16', latex_label='Grad_16', unit=None, boundary=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results do not exist in : outdir/calibration_grad_ptb_addstepasym/addstepasym_mix\n",
      "The following Default settings for sampler will be used. You can change    these arguments by providing kwargs_for_sampler argement in `train`.    Check Bilby documentation for other sampling options.\n",
      "{'sampler': 'ptemcee', 'ntemps': 10, 'nwalkers': 200, 'Tmax': 100, 'burn_in_fixed_discard': 500, 'nsamples': 8000, 'threads': 7, 'printdt': 60}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:43 bilby INFO    : Single likelihood evaluation took 1.764e-02 s\n",
      "14:43 bilby WARNING : Supplied argument 'printdt' not an argument of 'Ptemcee', removing.\n",
      "14:43 bilby INFO    : Using sampler Ptemcee with kwargs {'ntemps': 10, 'nwalkers': 200, 'Tmax': 100, 'betas': None, 'a': 2.0, 'adaptation_lag': 10000, 'adaptation_time': 100, 'random': None, 'adapt': False, 'swap_ratios': False}\n",
      "14:43 bilby INFO    : Using convergence inputs: ConvergenceInputs(autocorr_c=5, autocorr_tol=50, autocorr_tau=1, gradient_tau=0.1, gradient_mean_log_posterior=0.1, Q_tol=1.02, safety=1, burn_in_nact=50, burn_in_fixed_discard=500, mean_logl_frac=0.01, thin_by_nact=0.5, nsamples=8000, ignore_keys_for_tau=None, min_tau=1, niterations_per_check=5)\n",
      "14:43 bilby INFO    : Generating pos0 samples\n",
      "14:44 bilby INFO    : Starting to sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|0:00:41|nc:1.0e+04|a0:0.00-0.80|swp:0.41-0.77|n:nan<8000|t!nan(+nan,+nan)|q:inf|4.16ms/ev\n",
      "2|0:01:34|nc:2.0e+04|a0:0.00-0.80|swp:0.32-0.62|n:nan<8000|t!nan(+nan,+nan)|q:inf|4.71ms/ev\n",
      "3|0:02:28|nc:3.0e+04|a0:0.07-0.73|swp:0.25-0.53|n:nan<8000|t!nan(+nan,+nan)|q:inf|4.95ms/ev\n",
      "4|0:03:25|nc:4.0e+04|a0:0.10-0.65|swp:0.22-0.45|n:nan<8000|t!nan(+nan,+nan)|q:inf|5.47ms/ev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:48 bilby INFO    : Run interrupted by signal 2: checkpoint and exit on 77\n",
      "14:48 bilby INFO    : Writing checkpoint and diagnostics\n",
      "14:48 bilby INFO    : Finished writing checkpoint\n"
     ]
    }
   ],
   "source": [
    "#result = mix_model.train(x_exp=g, y_exp=exp_data[0], y_err=exp_data[1], outdir = 'outdir/samba_bivaraite', label='step_mix')\n",
    "outdir = 'outdir/calibration_grad_ptb_addstepasym'\n",
    "result = mix_model.train(x_exp=g, y_exp=exp_data[0], y_err=exp_data[1], outdir = outdir, label='addstepasym_mix', \n",
    "                        load_previous=True,)\n",
    "                        #kwargs_for_sampler=sampler_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior of the mixing parameters. \n",
    "sns.set_context('poster')\n",
    "result.plot_corner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a6548",
   "metadata": {},
   "source": [
    "## 4. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e90f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,mean_prior,CI_prior, _ = mix_model.prior_predict(g, CI=[5,20,80,95])\n",
    "_,mean,CI, _ = mix_model.predict(g, CI=[5,20,80,95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b186cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "per5, per20, per80, per95 = CI\n",
    "prior5, prior20, prior80, prior95 = CI_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "per5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2eb017",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_model.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853547e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map value prediction for the step mixing function parameter\n",
    "map_prediction = mix_model.evaluate(mix_model.map, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a66991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fig, ax_hist = plt.subplots(figsize=(10,10))\n",
    "sns.histplot(data=result.posterior, x='addstep_0', y='addstep_1', kde=True, ax=ax_hist)\n",
    "ax_hist.axvline(x = mix_model.map[0], color = 'r', label = f'MAP : {mix_model.map[0]:.3f}') \n",
    "ax_hist.axhline(y = mix_model.map[1], color = 'r', label = f'MAP : {mix_model.map[1]:.3f}') \n",
    "ax_hist.set_xlabel('Centrality')\n",
    "ax_hist.legend()\n",
    "os.makedirs(outdir+'/figures/', exist_ok = True)\n",
    "plt.tight_layout()\n",
    "fig.savefig(outdir+'/figures/'+'MAP_', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(result.posterior[['addstep_0','addstep_1','addstep_2']], kind='kde', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf59250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_context(\"notebook\", font_scale=1.5)\n",
    "#sns.set_style(\"ticks\")\n",
    "map_parameters=mix_model.map.flatten()\n",
    "sns.set_palette('bright')\n",
    "observables_to_plot=[0, 1, 2]\n",
    "gg = sns.PairGrid(result.posterior.iloc[:,observables_to_plot], corner=True, diag_sharey=False)\n",
    "gg.map_lower(sns.histplot, color=sns.color_palette()[4])\n",
    "#g.map_upper(sns.kdeplot, shade=True, color=sns.color_palette()[0])\n",
    "gg.map_diag(sns.kdeplot, linewidth=2, shade=True, color=sns.color_palette()[9])\n",
    "for n,i in enumerate(observables_to_plot):\n",
    "    ax=gg.axes[n][n]\n",
    "    ax.axvline(x=map_parameters[i], ls='--', c=sns.color_palette()[9])\n",
    "    ax.text(0,0.9,s= f'{map_parameters[i]:.3f}', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(outdir+'/figures/'+'posterior_', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,_ = mix_model.evaluate_weights(mix_model.map.flatten(),g)\n",
    "#w1,_ = mix_model.evaluate_weights(np.array([0.2, 0]),g)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "#ax.set_title('MAP')\n",
    "ax.plot(g, w1, label = 'MAP ' + str([f'{mp:.1f}' for mp in mix_model.map.flatten()]))\n",
    "ax.set_xlabel('Centrality')\n",
    "ax.set_ylabel('Model_1 weight')\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_tex_labels = {\n",
    "                    'dNch_deta' : r'$dN_{ch}/d\\eta$',\n",
    "                    'dN_dy_pion' : r'$dN_{\\pi}/dy$',\n",
    "                    'dN_dy_kaon' : r'$dN_{k}/dy$',\n",
    "                    'dN_dy_proton' : r'$dN_{p}/dy$',\n",
    "                    'dN_dy_Lambda' : r'$dN_{\\Lambda}/dy$',\n",
    "                    'dN_dy_Omega' : r'$dN_{\\Omega}/dy$',\n",
    "                    'dN_dy_Xi' : r'$dN_{\\Xi}/dy$',\n",
    "                    'dET_deta' : r'$dE_{T}/d\\eta$',\n",
    "                    'mean_pT_pion' : r'$\\langle p_T \\rangle _{\\pi}$',\n",
    "                    'mean_pT_kaon' : r'$\\langle p_T \\rangle _{k}$',\n",
    "                    'mean_pT_proton' : r'$\\langle p_T \\rangle _{p}$',\n",
    "                    'pT_fluct' : r'$\\delta p_T / \\langle p_T \\rangle$',\n",
    "                    'v22' : r'$v_2\\{2\\}$',\n",
    "                    'v32' : r'$v_3\\{2\\}$',\n",
    "                    'v42' : r'$v_4\\{2\\}$',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd156e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_prediction[0][:,i].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c050f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,4, figsize=(40,30))\n",
    "sns.set_context('poster')\n",
    "for i in range(0,12):\n",
    "    ax_f= axs.flatten()[i]\n",
    "    ax_f.errorbar(g, m1_prediction[0][:,i].flatten(), \n",
    "                yerr=m1_prediction[1][:,i].flatten(), \n",
    "                label='Grad', alpha=0.5)\n",
    "    ax_f.errorbar(g, m2_prediction[0][:,i].flatten(), \n",
    "                yerr=m1_prediction[1][:,i].flatten(),\n",
    "                label='PTB', alpha=0.5)\n",
    "    # ax_f.plot(plot_g, m1_prediction[0][:,i].flatten(),\n",
    "    #             label='Grad', alpha=0.8)\n",
    "    # ax_f.plot(plot_g, m2_prediction[0][:,i].flatten(), \n",
    "    #             label='PTB', alpha=0.8)\n",
    "    ax_f.plot(g, mean[0][i,:].flatten(), label='Mean BMM')\n",
    "    ax_f.plot(g, map_prediction[i,:].flatten(), label='MAP', color='k')\n",
    "    #ax_f.plot(plot_g, true_output[0], label='truth')\n",
    "    ax_f.scatter(g,exp_data[0][:,i].flatten(), marker='x', label='experimental data', color='r')\n",
    "    ax_f.set_xlabel('Centrality')\n",
    "    #ax_f.set_ylim(1.2,3.2)\n",
    "    ax_f.set_ylabel(obs_tex_labels[obs_names[i]])\n",
    "    if i ==0:\n",
    "        ax_f.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(outdir+'/figures/'+'MAP_', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "fig, axs = plt.subplots(3, 4, figsize=(40,30))\n",
    "for i in range(0,12):\n",
    "    ax = axs.flatten()[i]\n",
    "    #fig, ax = plt.subplots(figsize=(10,10))\n",
    "    #ax.plot(plot_g, mean[0][i,:].flatten(), label='posterior mean')\n",
    "    # ax_f.errorbar(plot_g, m1_prediction[0][:,i].flatten(), \n",
    "    #             yerr=m1_prediction[1][:,i].flatten(), \n",
    "    #             label='Grad', alpha=0.2)\n",
    "    # ax_f.errorbar(plot_g, m2_prediction[0][:,i].flatten(), \n",
    "    #             yerr=m1_prediction[1][:,i].flatten(),\n",
    "    #             label='PTB', alpha=0.2)\n",
    "    ax.plot(g, m1_prediction[0][:,i].flatten(),\n",
    "                label='Grad', alpha=0.8)\n",
    "    ax.plot(g, m2_prediction[0][:,i].flatten(), \n",
    "                label='PTB', alpha=0.8)\n",
    "    ax.fill_between(g,per5[0][i,:].flatten(),per95[0][i,:].flatten(),color=sns.color_palette()[4], alpha=0.8, label='90% C.I.')\n",
    "    ax.fill_between(g,per20[0][i,:].flatten(),per80[0][i,:].flatten(), color=sns.color_palette()[4], alpha=0.5, label='60% C.I.')\n",
    "    #ax.fill_between(plot_g,prior20[0][i,:].flatten(),prior80[0][i,:].flatten(),color=sns.color_palette()[2], alpha=0.2, label='60% C.I. Prior')\n",
    "    ax.scatter(g,exp_data[0][:,i].flatten(), marker='x', label='experimental data')\n",
    "    #ax.plot(plot_g, mean_prior[0][i,:].flatten(), label='prior mean')\n",
    "    ax.plot(g, map_prediction[i,:].flatten(), label='MAP prediction', color='r')\n",
    "    ax.set_xlabel('Centrality')\n",
    "    #ax_f.set_ylim(1.2,3.2)\n",
    "    ax.set_ylabel(obs_tex_labels[obs_names[i]])\n",
    "    if i==0:\n",
    "        ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(outdir+'/figures/'+'posterior_predict_', dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c460bb57a9a9b1bc7b0784a6ba6310fee28c94e738a9746efe1113ef0eaab8cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
